{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path as op\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ptitprince as pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "['subj01']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_list = ['FA', 'MD', 'RD'] #this should be an input argument\n",
    "TCK_NAME = 'extracted' #check with convention\n",
    "#path where all subjects live\n",
    "path_allsub = '/Users/alicja/Documents/Neurohackademy22/fsub'\n",
    "subjects = [ f.name for f in os.scandir(path_allsub) if f.is_dir() and 'sub' in f.name ]\n",
    "#get all subjects\n",
    "subjects\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/alicja/Documents/Neurohackademy22/fsub/subj01\n"
     ]
    }
   ],
   "source": [
    "print(op.join(path_allsub, subjects[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tck_files = [ f.path for f in os.scandir(op.join(path_allsub, subjects[0])) if f.is_file() if TCK_NAME in f.name ]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# fls = [ f.path for f in os.scandir(op.join(path_allsub, subjects[0])) if f.is_file() if 'stats.txt' in f.name ]\n",
    "\n",
    "fls = [ f.path for f in os.scandir(op.join(path_allsub, subjects[0])) if f.is_file()]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "['/Users/alicja/Documents/Neurohackademy22/fsub/subj01/.DS_Store',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/rh.floc-places.nii.gz',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/lh.floc-faces.nii.gz',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/fa.nii.gz',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/rh.floc-places.nii',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/track-merged.tck',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/lh.floc-places.nii.gz',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/RD_stats.txt',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/lh.floc-words.nii.gz',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/rh.floc-faces.nii.gz',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/test.png',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/rh.floc-bodies.nii.gz',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/md.nii.gz',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/lh.floc-bodies.nii.gz',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/rh.floc-words.nii.gz',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/extracted.tck',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/FA_stats.txt',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/rh.floc-faces.nii',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/rd.nii.gz',\n '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/MD_stats.txt']"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fls"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_means(filename):\n",
    "    '''\n",
    "    Reads the tcksample output to get tract statistics\n",
    "    :param filename: a path with the filename to the file containing the values, output of the tcksample command\n",
    "    :return: a list with the values in floating point values\n",
    "    '''\n",
    "    with open(filename) as f:\n",
    "        return [float(val) for val in f.read().splitlines()[1].split(' ')]\n",
    "\n",
    "def proces_subject(sub, stats, plot = True):\n",
    "    '''\n",
    "    processes a single subject from the given path\n",
    "    :param sub: string, subject name; a string\n",
    "    :param stats: a list of strings, the statistics we are interested in\n",
    "    :param plot: boolean, should it export plots for the statistics, default is True\n",
    "    :return: none\n",
    "    '''\n",
    "    path = '/Users/alicja/Documents/Neurohackademy22/fsub/subj01/' #path to subject\n",
    "    inlist = []\n",
    "\n",
    "    # [TODO] generate the statistic files with mrtrix commandline \"tcksample\" command\n",
    "\n",
    "    #directory to the file containing statistics per streamline in the segmented data\n",
    "    for stat in stats:\n",
    "        inlist.append(op.join(path, stat))\n",
    "\n",
    "    stat_dict = {}\n",
    "\n",
    "    for stat, infile in zip(stats, inlist):\n",
    "        stat_dict[stat] = extract_means(infile)\n",
    "\n",
    "    #gather the data into a single dataframe\n",
    "    stat_df = pd.DataFrame(stat_dict)\n",
    "    stat_df.reset_index(inplace = True)\n",
    "    stat_df = stat_df.rename(columns = {'index':'streamline'})\n",
    "    stat_df['streamline'] = stat_df['streamline']+1\n",
    "\n",
    "    #make a tidy dataframe 'Stats' with the values for all the statistics - not used at the moment, might be used later\n",
    "    stat_melted = pd.melt(stat_df,\n",
    "                          ['streamline'],\n",
    "                          var_name='measurement',\n",
    "                          value_name='value')\n",
    "\n",
    "    stats_tidy = Stat_melted.sort_values(by=['streamline'], ignore_index=True)\n",
    "\n",
    "    # #Just checking\n",
    "    # print('FA Mean:\\t', np.mean(stat_df['FA']), '\\nFA SD:\\t\\t', np.std(stat_df['FA']))\n",
    "    # print('MD Mean:\\t', np.mean(stat_df['MD']), '\\nMD SD:\\t\\t', np.std(stat_df['MD']))\n",
    "    # print('RD Mean:\\t', np.mean(stat_df['RD']), '\\nMD SD:\\t\\t', np.std(stat_df['RD']))\n",
    "\n",
    "    #write the full statistics per streamline and the mean of all streamlines to a .tsv file\n",
    "    stat_df.to_csv('Stats_per_streamline.tsv', sep = '\\t', index = False)\n",
    "    #you can also do that for the tidy data\n",
    "    # Stats_tidy.to_csv('Tidy_stats.tsv', sep = '\\t', index = False)\n",
    "\n",
    "    #write summary statistics\n",
    "    with open(r'Summary_statistics_out.tsv', 'w') as fp:\n",
    "        #column names\n",
    "        fp.write('Stat\\tMean\\tSD\\n')\n",
    "        #contents\n",
    "        for stat in stats:\n",
    "            mean_stat = np.mean(stat_df[stat])\n",
    "            sd_stat = np.std(stat_df[stat])\n",
    "            fp.write(stat + '\\t' + str(mean_stat) + '\\t' + str(sd_stat) + '\\n')\n",
    "\n",
    "    if plot:\n",
    "        #plot the values and statistics\n",
    "        for stat in stats:\n",
    "\n",
    "            sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "            pal = 'viridis'\n",
    "            d = stat_df\n",
    "            dy = stat_df[stat]\n",
    "\n",
    "            ax, fig = plt.subplots(figsize=(4, 10))\n",
    "\n",
    "            #all of the individual values\n",
    "            ax = sns.stripplot(data = d,\n",
    "                               y = dy,\n",
    "                               size = 10,\n",
    "                               alpha = 0.25,\n",
    "                               #hue = d['streamline'],\n",
    "                               palette = pal)\n",
    "            #mean and SD\n",
    "            ax = sns.pointplot(data = d,\n",
    "                               y = dy,\n",
    "                               ci = 'sd',\n",
    "                               scale = 1.5,\n",
    "                               palette = pal)\n",
    "            #distriibution\n",
    "            ax = pt.half_violinplot(data = d,\n",
    "                                    y = dy,\n",
    "                                    bw = .3,\n",
    "                                    cut = 0.,\n",
    "                                    alpha = 0.4,\n",
    "                                    scale = \"area\",\n",
    "                                    width = .3,\n",
    "                                    inner = None,\n",
    "                                    linewidth=0,\n",
    "                                    palette = pal)\n",
    "\n",
    "            #set axes limit\n",
    "            plt.ylim(0, 1.1*max(dy))\n",
    "            #add a caption\n",
    "            text = 'Mean ' + stat + ': '+ str(np.mean(dy)) + '\\nSD: ' + str(np.std(dy))\n",
    "            plt.text(-0.4, 0.1*max(dy), text)\n",
    "            #make it pretty\n",
    "            sns.despine()\n",
    "\n",
    "            #don't show the plot\n",
    "            plt.close()\n",
    "            #save to a file\n",
    "            plt.savefig(op.join(path, sub, stat + '_visuals.png'), dpi = 300)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 1\n",
      "b 2\n"
     ]
    }
   ],
   "source": [
    "dc = {'a': 1, 'b': 2}\n",
    "for d in dc:\n",
    "    print( d, dc[d])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "with open('/Users/alicja/Documents/Neurohackademy22/fsub/subj01/FA_hand_stats.txt') as f:\n",
    "\to = [float(val) for val in f.read().splitlines()[1].split(' ')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.4739239812,\n 0.4160107374,\n 0.3768298924,\n 0.3602295816,\n 0.3719401062,\n 0.4185263515,\n 0.4142763913,\n 0.4246834815,\n 0.441195786,\n 0.460630089,\n 0.4539869726,\n 0.3828779459,\n 0.3984600604,\n 0.3780937791,\n 0.3692632616,\n 0.4159753621,\n 0.3743050694,\n 0.3978762329,\n 0.3855750263,\n 0.4558957219,\n 0.3673609495,\n 0.4692897499,\n 0.4229521155,\n 0.4020593166,\n 0.4544655085,\n 0.4721446633,\n 0.3807932734,\n 0.4182381332,\n 0.3577736914,\n 0.3783694506,\n 0.388325274,\n 0.3695614934,\n 0.4361559153,\n 0.4410347641,\n 0.4683634937,\n 0.4122210443,\n 0.4407535791,\n 0.4170628488,\n 0.4699370563,\n 0.3951056898,\n 0.4182701111,\n 0.4575459361,\n 0.4281986058,\n 0.4230111241,\n 0.4045489132,\n 0.4509513974,\n 0.4417990446,\n 0.4691022336,\n 0.411771059,\n 0.4452429414,\n 0.3657073081,\n 0.3906688392,\n 0.366422683,\n 0.4010700285,\n 0.3970649838,\n 0.3868813515,\n 0.4442676008,\n 0.350672245,\n 0.4313034415,\n 0.3514466584,\n 0.4298926592,\n 0.4718409479,\n 0.4481250942,\n 0.4346090853,\n 0.5025451183,\n 0.4367377162,\n 0.5274486542,\n 0.3799201548,\n 0.3846026957,\n 0.400454849,\n 0.4326654077,\n 0.505476892,\n 0.473621875]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}